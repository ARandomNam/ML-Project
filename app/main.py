"""
Resume Match Score Predictor - Streamlitä¸»åº”ç”¨
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from io import StringIO
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.nlp.text_processor import TextProcessor
from app.nlp.similarity import SimilarityCalculator
from app.utils.file_handler import FileHandler


def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'processor' not in st.session_state:
        st.session_state.processor = TextProcessor()
    if 'calculator' not in st.session_state:
        st.session_state.calculator = SimilarityCalculator()
    if 'file_handler' not in st.session_state:
        st.session_state.file_handler = FileHandler()


def create_score_gauge(score):
    """åˆ›å»ºåˆ†æ•°ä»ªè¡¨ç›˜"""
    fig = go.Figure(go.Indicator(
        mode = "gauge+number+delta",
        value = score,
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {'text': "åŒ¹é…åˆ†æ•°"},
        delta = {'reference': 50},
        gauge = {
            'axis': {'range': [None, 100]},
            'bar': {'color': "darkblue"},
            'steps': [
                {'range': [0, 25], 'color': "lightgray"},
                {'range': [25, 50], 'color': "yellow"},
                {'range': [50, 75], 'color': "orange"},
                {'range': [75, 100], 'color': "green"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 80
            }
        }
    ))
    
    fig.update_layout(height=300)
    return fig


def create_skills_chart(skill_analysis):
    """åˆ›å»ºæŠ€èƒ½åˆ†æå›¾è¡¨"""
    matched_count = len(skill_analysis['matched_skills'])
    missing_count = len(skill_analysis['missing_skills'])
    extra_count = len(skill_analysis['extra_skills'])
    
    labels = ['åŒ¹é…æŠ€èƒ½', 'ç¼ºå¤±æŠ€èƒ½', 'é¢å¤–æŠ€èƒ½']
    values = [matched_count, missing_count, extra_count]
    colors = ['#00cc96', '#ef553b', '#636efa']
    
    fig = px.pie(
        values=values, 
        names=labels, 
        title="æŠ€èƒ½åˆ†å¸ƒ",
        color_discrete_sequence=colors
    )
    
    fig.update_layout(height=400)
    return fig


def display_keywords_analysis(keyword_analysis):
    """å±•ç¤ºå…³é”®è¯åˆ†æç»“æœ"""
    st.subheader("ğŸ” å…³é”®è¯åˆ†æ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric(
            "å…³é”®è¯åŒ¹é…ç‡", 
            f"{keyword_analysis['overlap_ratio']*100:.1f}%",
            f"{keyword_analysis['matched_count']}/{keyword_analysis['total_job_keywords']}"
        )
    
    with col2:
        st.metric(
            "åŒ¹é…å…³é”®è¯æ•°é‡", 
            keyword_analysis['matched_count'],
            f"æ€»å…± {keyword_analysis['total_job_keywords']} ä¸ªå…³é”®è¯"
        )
    
    if keyword_analysis['matched_keywords']:
        st.success("âœ… **åŒ¹é…çš„å…³é”®è¯:**")
        matched_text = ", ".join(keyword_analysis['matched_keywords'][:20])
        if len(keyword_analysis['matched_keywords']) > 20:
            matched_text += f" ... (è¿˜æœ‰ {len(keyword_analysis['matched_keywords'])-20} ä¸ª)"
        st.write(matched_text)
    
    if keyword_analysis['missing_keywords']:
        st.warning("âš ï¸ **ç¼ºå¤±çš„å…³é”®è¯:**")
        missing_text = ", ".join(keyword_analysis['missing_keywords'][:20])
        if len(keyword_analysis['missing_keywords']) > 20:
            missing_text += f" ... (è¿˜æœ‰ {len(keyword_analysis['missing_keywords'])-20} ä¸ª)"
        st.write(missing_text)


def display_skills_analysis(skill_analysis):
    """å±•ç¤ºæŠ€èƒ½åˆ†æç»“æœ"""
    st.subheader("ğŸ’¼ æŠ€èƒ½åˆ†æ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric(
            "æŠ€èƒ½åŒ¹é…ç‡", 
            f"{skill_analysis['skill_match_ratio']*100:.1f}%",
            f"{skill_analysis['matched_skills_count']}/{skill_analysis['total_required_skills']}"
        )
    
    with col2:
        # åˆ›å»ºæŠ€èƒ½åˆ†å¸ƒå›¾
        if any([skill_analysis['matched_skills'], skill_analysis['missing_skills'], skill_analysis['extra_skills']]):
            fig = create_skills_chart(skill_analysis)
            st.plotly_chart(fig, use_container_width=True)
    
    # æŠ€èƒ½è¯¦æƒ…
    if skill_analysis['matched_skills']:
        st.success("âœ… **åŒ¹é…çš„æŠ€èƒ½:**")
        st.write(", ".join(skill_analysis['matched_skills']))
    
    if skill_analysis['missing_skills']:
        st.error("âŒ **ç¼ºå¤±çš„æŠ€èƒ½:**")
        st.write(", ".join(skill_analysis['missing_skills']))
    
    if skill_analysis['extra_skills']:
        st.info("â• **é¢å¤–çš„æŠ€èƒ½:**")
        st.write(", ".join(skill_analysis['extra_skills']))


def create_scores_dataframe(analysis_result, weights):
    """åˆ›å»ºåˆ†æ•°æ•°æ®æ¡†"""
    scores_data = [
        {
            "æŒ‡æ ‡": "TF-IDFç›¸ä¼¼åº¦",
            "åˆ†æ•°": f"{analysis_result['scores']['tfidf_similarity']:.3f}",
            "æƒé‡": f"{weights.get('tfidf_similarity', 0):.2f}"
        },
        {
            "æŒ‡æ ‡": "spaCyè¯­ä¹‰ç›¸ä¼¼åº¦",
            "åˆ†æ•°": f"{analysis_result['scores']['spacy_similarity'] or 0:.3f}",
            "æƒé‡": f"{weights.get('spacy_similarity', 0):.2f}"
        },
        {
            "æŒ‡æ ‡": "å…³é”®è¯é‡å åº¦",
            "åˆ†æ•°": f"{analysis_result['scores']['keyword_overlap']:.3f}",
            "æƒé‡": f"{weights.get('keyword_overlap', 0):.2f}"
        },
        {
            "æŒ‡æ ‡": "æŠ€èƒ½åŒ¹é…åº¦",
            "åˆ†æ•°": f"{analysis_result['scores']['skill_match']:.3f}",
            "æƒé‡": f"{weights.get('skill_match', 0):.2f}"
        }
    ]
    
    # æ·»åŠ PyTorchæ·±åº¦å­¦ä¹ åˆ†æ•°
    if analysis_result.get('deep_learning_available') and 'pytorch_similarity' in analysis_result['scores']:
        scores_data.append({
            "æŒ‡æ ‡": "ğŸš€ PyTorchç»¼åˆ",
            "åˆ†æ•°": f"{analysis_result['scores']['pytorch_similarity']:.3f}",
            "æƒé‡": f"{weights.get('pytorch_similarity', 0):.2f}"
        })
        
        # æ·»åŠ å„ä¸ªæ¨¡å‹çš„è¯¦ç»†åˆ†æ•°
        if 'sentence_bert' in analysis_result['scores']:
            scores_data.append({
                "æŒ‡æ ‡": "ğŸ“Š Sentence-BERT",
                "åˆ†æ•°": f"{analysis_result['scores']['sentence_bert']:.3f}",
                "æƒé‡": "å­æ¨¡å‹"
            })
        
        if 'sentence_bert_large' in analysis_result['scores']:
            scores_data.append({
                "æŒ‡æ ‡": "ğŸ¯ BERT-Large",
                "åˆ†æ•°": f"{analysis_result['scores']['sentence_bert_large']:.3f}",
                "æƒé‡": "å­æ¨¡å‹"
            })
            
        if 'bert_base' in analysis_result['scores']:
            scores_data.append({
                "æŒ‡æ ‡": "ğŸ”§ BERT-Base",
                "åˆ†æ•°": f"{analysis_result['scores']['bert_base']:.3f}",
                "æƒé‡": "å­æ¨¡å‹"
            })
    
    return pd.DataFrame(scores_data)


def main():
    st.set_page_config(
        page_title="Resume Match Score Predictor",
        page_icon="ğŸ¯",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    init_session_state()
    
    # æ ‡é¢˜å’Œæè¿°
    st.title("ğŸ¯ Resume Match Score Predictor")
    st.markdown("---")
    st.markdown(
        """
        è¿™æ˜¯ä¸€ä¸ªåŸºäºNLPçš„æ™ºèƒ½ç®€å†åŒ¹é…å·¥å…·ï¼Œèƒ½å¤Ÿåˆ†æç®€å†ä¸èŒä½æè¿°çš„åŒ¹é…åº¦ï¼Œ
        å¹¶æä¾›è¯¦ç»†çš„å…³é”®è¯å’ŒæŠ€èƒ½åˆ†ææŠ¥å‘Šã€‚
        """
    )
    
    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        
        # åˆ†ææ–¹æ³•é€‰æ‹©
        st.subheader("åˆ†ææ–¹æ³•")
        use_tfidf = st.checkbox("TF-IDF ç›¸ä¼¼åº¦", value=True)
        use_spacy = st.checkbox("spaCy è¯­ä¹‰ç›¸ä¼¼åº¦", value=st.session_state.calculator.spacy_available)
        use_keywords = st.checkbox("å…³é”®è¯åŒ¹é…", value=True)
        use_skills = st.checkbox("æŠ€èƒ½åŒ¹é…", value=True)
        
        # æ·±åº¦å­¦ä¹ é€‰é¡¹
        deep_learning_available = getattr(st.session_state.calculator, 'deep_learning_available', False)
        use_sentence_bert = st.checkbox(
            "ğŸš€ PyTorch æ·±åº¦å­¦ä¹ ", 
            value=deep_learning_available,
            help="ä½¿ç”¨PyTorchå’ŒBERTæ¨¡å‹è¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—" if deep_learning_available else "éœ€è¦å®‰è£…PyTorchæ·±åº¦å­¦ä¹ ä¾èµ–"
        )
        
        if deep_learning_available:
            model_info = getattr(st.session_state.calculator.dl_calculator, 'get_model_info', lambda: {})()
            if model_info.get('available'):
                st.success(f"ğŸ¯ æ·±åº¦å­¦ä¹ å·²å¯ç”¨ | è®¾å¤‡: {model_info.get('device', 'CPU')}")
                if model_info.get('cuda_available'):
                    st.info("âš¡ GPU åŠ é€Ÿå¯ç”¨")
        else:
            st.warning("âš ï¸ PyTorchæ·±åº¦å­¦ä¹ åŠŸèƒ½æœªå¯ç”¨ï¼Œè¯·è¿è¡Œ: pip install torch sentence-transformers transformers")
        
        # æƒé‡è°ƒæ•´
        st.subheader("æƒé‡è®¾ç½®")
        if use_tfidf:
            tfidf_weight = st.slider("TF-IDFæƒé‡", 0.0, 1.0, 0.3, 0.05)
        else:
            tfidf_weight = 0.0
            
        if use_spacy and st.session_state.calculator.spacy_available:
            spacy_weight = st.slider("spaCyæƒé‡", 0.0, 1.0, 0.2, 0.05)
        else:
            spacy_weight = 0.0
            
        if use_keywords:
            keyword_weight = st.slider("å…³é”®è¯æƒé‡", 0.0, 1.0, 0.25, 0.05)
        else:
            keyword_weight = 0.0
            
        if use_skills:
            skill_weight = st.slider("æŠ€èƒ½æƒé‡", 0.0, 1.0, 0.25, 0.05)
        else:
            skill_weight = 0.0
            
        if use_sentence_bert and deep_learning_available:
            pytorch_weight = st.slider("PyTorchæ·±åº¦å­¦ä¹ æƒé‡", 0.0, 1.0, 0.25, 0.05)
        else:
            pytorch_weight = 0.0
        
        # æ ‡å‡†åŒ–æƒé‡
        total_weight = tfidf_weight + spacy_weight + keyword_weight + skill_weight + pytorch_weight
        if total_weight > 0:
            weights = {
                'tfidf_similarity': tfidf_weight / total_weight,
                'spacy_similarity': spacy_weight / total_weight,
                'keyword_overlap': keyword_weight / total_weight,
                'skill_match': skill_weight / total_weight,
                'pytorch_similarity': pytorch_weight / total_weight
            }
        else:
            weights = None
            st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ç§åˆ†ææ–¹æ³•ï¼")
    
    # ä¸»ç•Œé¢
    tab1, tab2, tab3 = st.tabs(["ğŸ“„ æ–‡æœ¬åˆ†æ", "ğŸ“ æ–‡ä»¶ä¸Šä¼ ", "ğŸ“Š ç¤ºä¾‹åˆ†æ"])
    
    with tab1:
        st.header("æ–‡æœ¬è¾“å…¥åˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ç®€å†å†…å®¹")
            resume_text = st.text_area(
                "è¯·è¾“å…¥ç®€å†å†…å®¹:",
                height=300,
                placeholder="è¯·ç²˜è´´ç®€å†æ–‡æœ¬å†…å®¹..."
            )
        
        with col2:
            st.subheader("èŒä½æè¿°")
            job_text = st.text_area(
                "è¯·è¾“å…¥èŒä½æè¿°:",
                height=300,
                placeholder="è¯·ç²˜è´´èŒä½æè¿°å†…å®¹..."
            )
        
        if st.button("å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
            if resume_text and job_text and weights:
                with st.spinner("æ­£åœ¨åˆ†æï¼Œè¯·ç¨å€™..."):
                    # é¢„å¤„ç†æ–‡æœ¬
                    resume_data = st.session_state.processor.preprocess_for_matching(resume_text)
                    job_data = st.session_state.processor.preprocess_for_matching(job_text)
                    
                    # è®¡ç®—ç›¸ä¼¼åº¦
                    analysis_result = st.session_state.calculator.calculate_comprehensive_score(
                        resume_data, job_data, weights
                    )
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.success("åˆ†æå®Œæˆï¼")
                    
                    # æ€»åˆ†æ˜¾ç¤º
                    col1, col2 = st.columns([1, 2])
                    
                    with col1:
                        st.plotly_chart(
                            create_score_gauge(analysis_result['percentage_score']),
                            use_container_width=True
                        )
                    
                    with col2:
                        st.subheader("ğŸ“ˆ è¯¦ç»†åˆ†æ•°")
                        scores_df = create_scores_dataframe(analysis_result, weights)
                        st.dataframe(scores_df, use_container_width=True)
                        
                        # æ˜¾ç¤ºæ·±åº¦å­¦ä¹ æ¨¡å‹ä¿¡æ¯
                        if analysis_result.get('deep_learning_available'):
                            model_info = analysis_result.get('model_info', {})
                            if model_info.get('available'):
                                st.caption(f"ğŸ’¡ æ·±åº¦å­¦ä¹ : {model_info.get('device', 'CPU')} | æ¨¡å‹æ•°é‡: {len(model_info.get('models', []))}")
                    
                    # åŒ¹é…è§£é‡Š
                    st.subheader("ğŸ“ åŒ¹é…åˆ†ææŠ¥å‘Š")
                    explanation = st.session_state.calculator.get_match_explanation(analysis_result)
                    st.info(explanation)
                    
                    # è¯¦ç»†åˆ†æ
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        display_keywords_analysis(analysis_result['keyword_analysis'])
                    
                    with col2:
                        display_skills_analysis(analysis_result['skill_analysis'])
            
            else:
                st.error("è¯·è¾“å…¥ç®€å†å’ŒèŒä½æè¿°å†…å®¹ï¼Œå¹¶é€‰æ‹©è‡³å°‘ä¸€ç§åˆ†ææ–¹æ³•ï¼")
    
    with tab2:
        st.header("æ–‡ä»¶ä¸Šä¼ åˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ä¸Šä¼ ç®€å†æ–‡ä»¶")
            resume_file = st.file_uploader(
                "é€‰æ‹©ç®€å†æ–‡ä»¶",
                type=['pdf', 'docx', 'txt'],
                help="æ”¯æŒPDFã€DOCXã€TXTæ ¼å¼"
            )
            
            resume_text_from_file = ""
            if resume_file:
                with st.spinner("æ­£åœ¨å¤„ç†ç®€å†æ–‡ä»¶..."):
                    result = st.session_state.file_handler.process_uploaded_file(
                        resume_file.read(), resume_file.name
                    )
                    
                    if result['success']:
                        resume_text_from_file = result['text']
                        st.success(f"âœ… æˆåŠŸå¤„ç†æ–‡ä»¶: {result['filename']}")
                        with st.expander("æŸ¥çœ‹æå–çš„æ–‡æœ¬"):
                            st.text_area("æå–çš„ç®€å†å†…å®¹", resume_text_from_file, height=200)
                    else:
                        st.error(f"âŒ å¤„ç†å¤±è´¥: {result['error']}")
        
        with col2:
            st.subheader("èŒä½æè¿°")
            job_text_for_file = st.text_area(
                "è¯·è¾“å…¥èŒä½æè¿°:",
                height=300,
                placeholder="è¯·ç²˜è´´èŒä½æè¿°å†…å®¹...",
                key="job_text_file"
            )
        
        if st.button("åˆ†æä¸Šä¼ æ–‡ä»¶", type="primary", use_container_width=True, key="analyze_file"):
            if resume_text_from_file and job_text_for_file and weights:
                with st.spinner("æ­£åœ¨åˆ†æï¼Œè¯·ç¨å€™..."):
                    # é¢„å¤„ç†æ–‡æœ¬
                    resume_data = st.session_state.processor.preprocess_for_matching(resume_text_from_file)
                    job_data = st.session_state.processor.preprocess_for_matching(job_text_for_file)
                    
                    # è®¡ç®—ç›¸ä¼¼åº¦
                    analysis_result = st.session_state.calculator.calculate_comprehensive_score(
                        resume_data, job_data, weights
                    )
                    
                    # æ˜¾ç¤ºç»“æœï¼ˆåŒtab1çš„ç»“æœæ˜¾ç¤ºé€»è¾‘ï¼‰
                    st.success("æ–‡ä»¶åˆ†æå®Œæˆï¼")
                    
                    col1, col2 = st.columns([1, 2])
                    
                    with col1:
                        st.plotly_chart(
                            create_score_gauge(analysis_result['percentage_score']),
                            use_container_width=True
                        )
                    
                    with col2:
                        st.subheader("ğŸ“ˆ è¯¦ç»†åˆ†æ•°")
                        scores_df = create_scores_dataframe(analysis_result, weights)
                        st.dataframe(scores_df, use_container_width=True)
                        
                        # æ˜¾ç¤ºæ·±åº¦å­¦ä¹ æ¨¡å‹ä¿¡æ¯
                        if analysis_result.get('deep_learning_available'):
                            model_info = analysis_result.get('model_info', {})
                            if model_info.get('available'):
                                st.caption(f"ğŸ’¡ æ·±åº¦å­¦ä¹ : {model_info.get('device', 'CPU')} | æ¨¡å‹æ•°é‡: {len(model_info.get('models', []))}")
                    
                    # åŒ¹é…è§£é‡Š
                    st.subheader("ğŸ“ åŒ¹é…åˆ†ææŠ¥å‘Š")
                    explanation = st.session_state.calculator.get_match_explanation(analysis_result)
                    st.info(explanation)
                    
                    # è¯¦ç»†åˆ†æ
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        display_keywords_analysis(analysis_result['keyword_analysis'])
                    
                    with col2:
                        display_skills_analysis(analysis_result['skill_analysis'])
            
            else:
                st.error("è¯·ä¸Šä¼ ç®€å†æ–‡ä»¶å¹¶è¾“å…¥èŒä½æè¿°ï¼")
    
    with tab3:
        st.header("ç¤ºä¾‹æ•°æ®åˆ†æ")
        st.markdown("ä½¿ç”¨é¡¹ç›®å†…ç½®çš„ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤ºåˆ†æ")
        
        if st.button("åŠ è½½ç¤ºä¾‹æ•°æ®å¹¶åˆ†æ", type="primary"):
            try:
                # è¯»å–ç¤ºä¾‹æ•°æ®
                with open('data/sample/sample_resume.txt', 'r', encoding='utf-8') as f:
                    sample_resume = f.read()
                
                with open('data/sample/sample_job_description.txt', 'r', encoding='utf-8') as f:
                    sample_job = f.read()
                
                with st.spinner("æ­£åœ¨åˆ†æç¤ºä¾‹æ•°æ®..."):
                    # é¢„å¤„ç†æ–‡æœ¬
                    resume_data = st.session_state.processor.preprocess_for_matching(sample_resume)
                    job_data = st.session_state.processor.preprocess_for_matching(sample_job)
                    
                    # è®¡ç®—ç›¸ä¼¼åº¦
                    analysis_result = st.session_state.calculator.calculate_comprehensive_score(
                        resume_data, job_data, weights
                    )
                    
                    st.success("ç¤ºä¾‹åˆ†æå®Œæˆï¼")
                    
                    # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("ç¤ºä¾‹ç®€å†")
                        st.text_area("", sample_resume, height=200, key="sample_resume_display")
                    
                    with col2:
                        st.subheader("ç¤ºä¾‹èŒä½æè¿°")
                        st.text_area("", sample_job, height=200, key="sample_job_display")
                    
                    # åˆ†æç»“æœ
                    col1, col2 = st.columns([1, 2])
                    
                    with col1:
                        st.plotly_chart(
                            create_score_gauge(analysis_result['percentage_score']),
                            use_container_width=True
                        )
                    
                    with col2:
                        st.subheader("ğŸ“ˆ è¯¦ç»†åˆ†æ•°")
                        scores_df = create_scores_dataframe(analysis_result, weights)
                        st.dataframe(scores_df, use_container_width=True)
                        
                        # æ˜¾ç¤ºæ·±åº¦å­¦ä¹ æ¨¡å‹ä¿¡æ¯
                        if analysis_result.get('deep_learning_available'):
                            model_info = analysis_result.get('model_info', {})
                            if model_info.get('available'):
                                st.caption(f"ğŸ’¡ æ·±åº¦å­¦ä¹ : {model_info.get('device', 'CPU')} | æ¨¡å‹æ•°é‡: {len(model_info.get('models', []))}")
                    
                    # åŒ¹é…è§£é‡Š
                    st.subheader("ğŸ“ åŒ¹é…åˆ†ææŠ¥å‘Š")
                    explanation = st.session_state.calculator.get_match_explanation(analysis_result)
                    st.info(explanation)
                    
                    # è¯¦ç»†åˆ†æ
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        display_keywords_analysis(analysis_result['keyword_analysis'])
                    
                    with col2:
                        display_skills_analysis(analysis_result['skill_analysis'])
            
            except FileNotFoundError:
                st.error("æ‰¾ä¸åˆ°ç¤ºä¾‹æ•°æ®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿data/sample/ç›®å½•ä¸‹æœ‰ç¤ºä¾‹æ–‡ä»¶ã€‚")
            except Exception as e:
                st.error(f"åˆ†æç¤ºä¾‹æ•°æ®æ—¶å‡ºé”™ï¼š{str(e)}")
    
    # é¡µè„š
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center'>
            <p>ğŸ¯ Resume Match Score Predictor | 
            åŸºäºNLPçš„æ™ºèƒ½ç®€å†åŒ¹é…å·¥å…· | 
            Powered by Streamlit</p>
        </div>
        """, 
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main() 